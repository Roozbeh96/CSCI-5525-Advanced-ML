Deep learning models have been using optimization methods based on gradients for training neural networks. While popular optimizers like ADAM, SGD, or more recent methods such as ADOPT are individually good at different aspects, no single optimizer is optimal across all training stages.
For example, some optimizers are great at quickly driving down the loss early in training but struggle to reach lower final loss values, while others are more stable but slower to converge. The problem, therefore, is to determine how to intelligently switch between different optimizers during training to leverage their complementary strengthsâ€”improving both the convergence rate and the final accuracy or loss. In this project, we implement a reinforcement learning agent to dynamically switch between two optimizers during the training process of an LSTM in a text classification problem.
